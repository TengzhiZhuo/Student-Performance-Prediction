{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import javalang\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "# import RNNmodel_2 as rnn\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from path_extractor import extracting_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', shape=(input_shape[-1],1), initializer='random_normal', trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias', shape=(input_shape[1],1), initializer='zeros', trainable=True)\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.squeeze(e, axis = -1)\n",
    "        alpha = K.softmax(e)\n",
    "        alpha = K.expand_dims(alpha, axis = -1)\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis = 1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student():\n",
    "    def __init__(self, ID, score, assignments):\n",
    "        self.ID = ID\n",
    "        self.score = score\n",
    "        self.assignments = assignments\n",
    "\n",
    "class Assignment(): \n",
    "    def __init__(self, ID, problems):\n",
    "        self.ID = ID\n",
    "        self.problems = problems\n",
    "\n",
    "class Problem(): \n",
    "    def __init__(self, ID, codeStates):\n",
    "        self.ID = ID\n",
    "        self.codeStates = codeStates\n",
    "\n",
    "class CodeState():\n",
    "    def __init__(self, ID, code, compileResult, compileMessageType, compileMessageData, score, time):\n",
    "        self.ID = ID\n",
    "        self.code = code\n",
    "        self.compileResult = compileResult\n",
    "        self.compileMessageType = compileMessageType\n",
    "        self.compileMessageData = compileMessageData\n",
    "        self.score = score\n",
    "        self.time = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    codeStates = {}\n",
    "    with open('./Datasets/CodeStates.csv', mode='r', encoding=\"utf8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            codeStates[line[0]] = line[1] \n",
    "            \n",
    "    mainTable = {}\n",
    "    with open('./Datasets/MainTable.csv', mode='r', encoding=\"utf8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            # Student\n",
    "            if line[0] not in mainTable:\n",
    "                mainTable[line[0]] = {}\n",
    "            # Assignment\n",
    "            if line[5] not in mainTable[line[0]]:\n",
    "                mainTable[line[0]][line[5]] = {}\n",
    "            # Problem\n",
    "            if line[6] not in mainTable[line[0]][line[5]]:\n",
    "                mainTable[line[0]][line[5]][line[6]] = {}\n",
    "            # CodeState\n",
    "            if line[7] not in mainTable[line[0]][line[5]][line[6]]:\n",
    "                # mainTable[Student][Assignment][Problem][Codestate]\n",
    "                mainTable[line[0]][line[5]][line[6]][line[7]] = {} \n",
    "            mainTable[line[0]][line[5]][line[6]][line[7]]['time'] = line[2]\n",
    "            mainTable[line[0]][line[5]][line[6]][line[7]]['code'] = codeStates[line[7]]\n",
    "            if line[10] != '':\n",
    "                mainTable[line[0]][line[5]][line[6]][line[7]]['score'] = line[10] \n",
    "            if line[11] != '':\n",
    "                mainTable[line[0]][line[5]][line[6]][line[7]]['compileResult'] = line[11]\n",
    "            if line[12] != '':\n",
    "                mainTable[line[0]][line[5]][line[6]][line[7]]['compileMessageType'] = line[12]\n",
    "                mainTable[line[0]][line[5]][line[6]][line[7]]['compileMessageData'] = line[13]\n",
    "    \n",
    "    studentScore = {}\n",
    "    with open('./Datasets/Subject.csv', mode='r', encoding=\"utf8\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            studentScore[line[0]] = line[1] \n",
    "\n",
    "    studentDataset = []\n",
    "    for student in tqdm(mainTable.keys()):\n",
    "        assignments = []\n",
    "        for assignment in mainTable[student]:\n",
    "            problems = []\n",
    "            for problem in mainTable[student][assignment]:\n",
    "                codeStates = []\n",
    "                for codeState in mainTable[student][assignment][problem]:\n",
    "                    compileMessageType = ''\n",
    "                    compileMessageData = ''\n",
    "                    if 'complieMessageType' in mainTable[student][assignment][problem][codeState]:\n",
    "                        compileMessageType = mainTable[student][assignment][problem][codeState]['compileMessageType']\n",
    "                        compileMessageData = mainTable[student][assignment][problem][codeState]['compileMessageData']\n",
    "                    cS = CodeState(\n",
    "                        codeState, \n",
    "                        mainTable[student][assignment][problem][codeState]['code'],\n",
    "                        mainTable[student][assignment][problem][codeState]['compileResult'],\n",
    "                        compileMessageType,\n",
    "                        compileMessageData,\n",
    "                        mainTable[student][assignment][problem][codeState]['score'],\n",
    "                        mainTable[student][assignment][problem][codeState]['time']\n",
    "                    )\n",
    "                    codeStates.append(cS)\n",
    "                pb = Problem(problem, codeStates)\n",
    "                problems.append(pb)\n",
    "            ass = Assignment(assignment, problems)\n",
    "            assignments.append(ass)\n",
    "        stu = Student(student, studentScore[student], assignments)\n",
    "        studentDataset.append(stu)\n",
    "\n",
    "    return np.array(studentDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:00<00:00, 1136.28it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_AST(code):\n",
    "    tokens = javalang.tokenizer.tokenize(code)\n",
    "    parser = javalang.parser.Parser(tokens)\n",
    "    tree = parser.parse_member_declaration()\n",
    "    return tree\n",
    "\n",
    "def fetch_codeState(students):\n",
    "    students_output = []\n",
    "    students_label = []\n",
    "    students_label_final_grade = []\n",
    "\n",
    "    for student in tqdm(students):\n",
    "        student_i = []\n",
    "        student_label_i = []\n",
    "        students_label_final_grade_i = []\n",
    "        final_grade = student.score\n",
    "        for assignment in student.assignments:\n",
    "            for problem in assignment.problems:\n",
    "                for codeState in problem.codeStates:\n",
    "                    try:\n",
    "                        parsed = code_to_AST(codeState.code)\n",
    "                    except:\n",
    "                        parsed = \"error\"\n",
    "                    label = codeState.score\n",
    "                    student_i.append(parsed)\n",
    "                    student_label_i.append(label)\n",
    "                    students_label_final_grade_i.append(final_grade)\n",
    "        hashing_table = {}\n",
    "        AST_paths = [extracting_path(java_code, max_length=8, max_width=2, hash_path=True, hashing_table=hashing_table) for java_code in student_i]\n",
    "        students_output.append(AST_paths)\n",
    "        students_label.append(student_label_i)\n",
    "        students_label_final_grade.append(students_label_final_grade_i)\n",
    "    \n",
    "    return students_output, students_label, students_label_final_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [17:26<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "students, lables, lables_final_grade = fetch_codeState(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_index_table(vocab):\n",
    "    \"\"\"\n",
    "    Creating word to index table\n",
    "    Input:\n",
    "    vocab: list. The list of the node vocabulary\n",
    "\n",
    "    \"\"\"\n",
    "    ixtoword = {}\n",
    "    # period at the end of the sentence. make first dimension be end token\n",
    "    ixtoword[0] = 'END'\n",
    "    ixtoword[1] = 'UNK'\n",
    "    wordtoix = {}\n",
    "    wordtoix['END'] = 0\n",
    "    wordtoix['UNK'] = 1\n",
    "    ix = 2\n",
    "    for w in vocab:\n",
    "        wordtoix[w] = ix\n",
    "        ixtoword[ix] = w\n",
    "        ix += 1\n",
    "    return wordtoix, ixtoword\n",
    "\n",
    "def convert_to_idx(sample, node_word_index, path_word_index):\n",
    "    \"\"\"\n",
    "    Converting to the index \n",
    "    Input:\n",
    "    sample: list. One single training sample, which is a code, represented as a list of neighborhoods.\n",
    "    node_word_index: dict. The node to word index dictionary.\n",
    "    path_word_index: dict. The path to word index dictionary.\n",
    "\n",
    "    \"\"\"\n",
    "    sample_index = []\n",
    "    for line in sample:\n",
    "        components = line.split(\",\")\n",
    "        if components[0] in node_word_index:\n",
    "            starting_node = node_word_index[components[0]]\n",
    "        else:\n",
    "            starting_node = node_word_index['UNK']\n",
    "        if components[1] in path_word_index:\n",
    "            path = path_word_index[components[1]]\n",
    "        else:\n",
    "            path = path_word_index['UNK']\n",
    "        if components[2] in node_word_index:\n",
    "            ending_node = node_word_index[components[2]]\n",
    "        else:\n",
    "            ending_node = node_word_index['UNK']\n",
    "        \n",
    "        sample_index.append([starting_node,path,ending_node])\n",
    "    return sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(students):\n",
    "    for student in students:\n",
    "        node_hist = {}\n",
    "        path_hist = {}\n",
    "        for paths in student:\n",
    "            starting_nodes = [p.split(\",\")[0] for p in paths]\n",
    "            path = [p.split(\",\")[1] for p in paths]\n",
    "            ending_nodes = [p.split(\",\")[2] for p in paths]\n",
    "            nodes = starting_nodes + ending_nodes\n",
    "            for n in nodes:\n",
    "                if not n in node_hist:\n",
    "                    node_hist[n] = 1\n",
    "                else:\n",
    "                    node_hist[n] += 1\n",
    "            for p in path:\n",
    "                if not p in path_hist:\n",
    "                    path_hist[p] = 1\n",
    "                else:\n",
    "                    path_hist[p] += 1\n",
    "        \n",
    "        # small frequency then abandon, for node and path\n",
    "        valid_node = [node for node, count in node_hist.items()]\n",
    "        valid_path = [path for path, count in path_hist.items()]\n",
    "\n",
    "        # create ixtoword and wordtoix lists\n",
    "        node_word_index, node_index_word = create_word_index_table(valid_node)\n",
    "        path_word_index, path_index_word = create_word_index_table(valid_path)\n",
    "\n",
    "    output = []\n",
    "    for student in students:\n",
    "        output_i = []\n",
    "        for paths in student:\n",
    "            raw_features = convert_to_idx(paths, node_word_index, path_word_index)\n",
    "            try:\n",
    "                features = np.array(raw_features).reshape(-1, len(raw_features*3))\n",
    "            except:\n",
    "                features = np.zeros(100)\n",
    "            output_i.append(features)\n",
    "        output.append(output_i)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = get_data(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(students, lables):\n",
    "    output = []\n",
    "    j = 0\n",
    "    for student in tqdm(students):\n",
    "        output_i = []\n",
    "        k = 0\n",
    "        for code in student:\n",
    "            code = np.resize(code, 300)\n",
    "            # code = code / np.linalg.norm(code)\n",
    "            toStore = {\n",
    "                \"codestate_array\": code,\n",
    "                \"codestate_label\": float(lables[j][k])\n",
    "            }\n",
    "            output_i.append(toStore)\n",
    "            k += 1\n",
    "        output.append(output_i)\n",
    "        j += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:00<00:00, 720.07it/s]\n"
     ]
    }
   ],
   "source": [
    "input = get_input(students, lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(layer_num, neuron_list, weights_list, instance):\n",
    "    pred = []\n",
    "    a_list = []\n",
    "    if weights_list is None:\n",
    "        weights_list = []\n",
    "        for i in range(layer_num + 1):\n",
    "            curweight = []\n",
    "            if i == layer_num:\n",
    "                weights = []\n",
    "                pre_layer_neuron_num = neuron_list[i - 1] + 1\n",
    "                for n in range(pre_layer_neuron_num):\n",
    "                    weights.append(random.uniform(-1.0, 1.0))\n",
    "                curweight.append(weights)\n",
    "            else:\n",
    "                for m in range(neuron_list[i]):\n",
    "                    weights = []\n",
    "                    pre_layer_neuron_num = 0\n",
    "                    if i == 0:\n",
    "                        pre_layer_neuron_num = len(instance[0]) + 1\n",
    "                    else:\n",
    "                        pre_layer_neuron_num = neuron_list[i-1] + 1\n",
    "                    for n in range(pre_layer_neuron_num):\n",
    "                        weights.append(random.uniform(-1.0, 1.0))\n",
    "                    curweight.append(weights)\n",
    "            weights_list.append(curweight)\n",
    "    #print(weights_list)\n",
    "    a1 = []\n",
    "    a1.append([1])\n",
    "    for i in instance[0]:\n",
    "        a1.append([i])\n",
    "    a = a1.copy()\n",
    "    n = 1\n",
    "    #print(\"a\" + str(n) + \": \" + str(a1))\n",
    "    a_list.append(a)\n",
    "    for layer in range(layer_num):\n",
    "        n += 1\n",
    "        z = np.dot(np.array(weights_list[layer]), np.array(a))\n",
    "        #print(\"z\" + str(n) + \": \" + str(z))\n",
    "        a = []\n",
    "        a.append([1])\n",
    "        for i in z:\n",
    "            try:\n",
    "                a.append([1 / (1 + math.exp(-i))])\n",
    "            except:\n",
    "                a.append([1 / float(\"inf\")])\n",
    "        a_list.append(a)\n",
    "        #print(\"a\" + str(n) + \": \" + str(a))\n",
    "    n += 1\n",
    "    z = np.dot(weights_list[-1], a)\n",
    "    #print(\"z\" + str(n) + \": \" + str(z))\n",
    "    a = []\n",
    "    for i in z:\n",
    "            try:\n",
    "                a.append([1 / (1 + math.exp(-i))])\n",
    "            except:\n",
    "                a.append([1 / float(\"inf\")])\n",
    "    pred = a\n",
    "    a_list.append(a)\n",
    "    #print(\"a\" + str(n) + \": \" + str(a))\n",
    "    #print(\"Predicted output for instance: \" + str(pred))\n",
    "    #print(\"Expected output for instance: \" + str(instance[1]))\n",
    "    return pred, a_list, weights_list\n",
    "\n",
    "def cost_function(layer_num, neuron_list, weights_list, ins, lambda_value):\n",
    "    J = 0\n",
    "    y = ins[1]\n",
    "    output = forward_propagation(layer_num, neuron_list, weights_list, ins)\n",
    "    weights_list = output[2]\n",
    "    J = abs(y[0] - output[0][0][0])\n",
    "    S = 0\n",
    "    for layer in weights_list:\n",
    "        for row in layer:\n",
    "            new_row = row[1:]\n",
    "            for r in new_row:\n",
    "                S += r*r\n",
    "    S *= (lambda_value / (2))\n",
    "    return J+S\n",
    "\n",
    "def backpropagation(layer_num, neuron_list, weights_list, instance, lambda_value):\n",
    "    ini_J = cost_function(layer_num, neuron_list, weights_list, instance, lambda_value)\n",
    "    D_list = []\n",
    "    for i in range(layer_num + 1):\n",
    "        D_list.append([])\n",
    "    output, a_list, wl = forward_propagation(layer_num, neuron_list, weights_list, instance)\n",
    "    weights_list = wl\n",
    "    y = []\n",
    "    delta_list = []\n",
    "    y.append([instance[1]])\n",
    "    delta = np.array(output[0]) - np.array(y[0])\n",
    "    delta_list.insert(0, delta)\n",
    "    #print(\"delta: \" + str(delta))\n",
    "    for num in range(layer_num):\n",
    "        curweight = weights_list[-num-1]\n",
    "        tweight = np.transpose(np.array(curweight))\n",
    "        delta = np.dot(tweight, delta)\n",
    "        for i in range(len(delta)):\n",
    "            delta[i][0] = delta[i][0] * a_list[-num-2][i][0] * (1-a_list[-num-2][i][0])\n",
    "        delta = delta[1:]\n",
    "        delta_list.insert(0, delta)\n",
    "        #print(\"delta: \" + str(delta))\n",
    "    for num in range(layer_num + 1):\n",
    "        cur = np.array(D_list[-num-1])\n",
    "        if len(cur) == 0:\n",
    "            D_list[-num - 1] = np.dot(delta_list[-num-1], np.transpose(a_list[-num-2]))\n",
    "        else:\n",
    "            D_list[-num-1] = cur + np.dot(delta_list[-num-1], np.transpose(a_list[-num-2]))\n",
    "    #for i in range(len(delta_list)):\n",
    "        #print(\"Gradients of Theta\" + str(len(delta_list) - i) + \" based on training instance: \" + str(np.dot(delta_list[-i-1], np.transpose(a_list[-i-2]))))\n",
    "    for layer in range(layer_num+1):\n",
    "        P = []\n",
    "        for w in weights_list[-layer-1]:\n",
    "            lst = []\n",
    "            for e in w:\n",
    "                lst.append(lambda_value * e)\n",
    "            lst[0] = 0\n",
    "            P.append(lst)\n",
    "        D_list[-layer-1] = 1 * (np.array(D_list[-layer-1]) + np.array(P))\n",
    "    #for i in range(len(D_list)):\n",
    "        #print(\"Final regularized gradients of Theta\" + str(i+1) + \": \" + str(D_list[i]))\n",
    "    for layer in range(layer_num+1):\n",
    "        weights_list[-layer-1] = np.array(weights_list[-layer-1]) - 2 * np.array(D_list[-layer-1])\n",
    "    cur_J = cost_function(layer_num, neuron_list, weights_list, instance, lambda_value)\n",
    "    if ini_J - cur_J < 0.001:\n",
    "        return weights_list\n",
    "    else:\n",
    "        return backpropagation(layer_num, neuron_list, weights_list, instance, lambda_value)\n",
    "\n",
    "def cal_performance(predictions, testset, classes):\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_F1 = 0\n",
    "    total_accuracy = 0\n",
    "    for curclass in classes:\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for i in range(len(predictions)):\n",
    "            actual = testset[i][1]\n",
    "            pred = predictions[i]\n",
    "            if pred == actual == curclass:\n",
    "                tp += 1\n",
    "            elif pred == curclass and actual != curclass:\n",
    "                fp += 1\n",
    "            elif pred != curclass and actual == curclass:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        if (fp + fn) == 0:\n",
    "            precision = 1\n",
    "            recall = 1\n",
    "            F1 = 1\n",
    "        elif (tp + fp) == 0:\n",
    "            precision = tn / (tn + fn)\n",
    "            recall = tp / (tp + fn)\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            F1 = 2 * ((precision * recall) / (precision + recall))\n",
    "        total_accuracy += accuracy\n",
    "        total_recall += recall\n",
    "        total_precision += precision\n",
    "        total_F1 += F1\n",
    "        #print(\"tp\" + str(tp) + \"tn\" + str(tn) + \"fp\" + str(fp) + \"fn\" + str(fn))\n",
    "    class_num = len(classes)\n",
    "    total_accuracy = total_accuracy / class_num\n",
    "    total_precision = total_precision / class_num\n",
    "    total_recall = total_recall / class_num\n",
    "    total_F1 = total_F1 / class_num\n",
    "    return total_accuracy, total_precision, total_recall, total_F1\n",
    "\n",
    "def run_rnn(trainingset, layer_num, neuron_list, lambda_value, weight_list, testingset, classes):\n",
    "    for instance in tqdm(trainingset):\n",
    "        weight_list = backpropagation(layer_num, neuron_list, weight_list, instance,lambda_value)\n",
    "    all_predictions = []\n",
    "    for j in tqdm(testingset):\n",
    "        prediction = forward_propagation(layer_num, neuron_list, weight_list, j)[0]\n",
    "        all_predictions.append(prediction)\n",
    "    accuracy, precision, recall, F1 = cal_performance(all_predictions, testingset, classes)\n",
    "    return accuracy, precision, recall, F1, weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing ONLY\n",
    "\n",
    "# trainingset = [[[0, 0, 0, 1, 1, 1], [3]] ,    [[1, 1, 0, 1, 0, 1], [4]]]\n",
    "# testingset = [[[0, 0, 1, 1, 1, 1], [4]] ,    [[1, 0, 0, 1, 0, 1], [3]]]\n",
    "# print(run_rnn(trainingset, 3, [3, 8, 8], 0.25, None, testingset, [0, 1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "# trainingset = []\n",
    "# testingset = []\n",
    "# for i in input[0]:\n",
    "#     trainingset.append([i[\"codestate_array\"], [i[\"codestate_label\"]]])\n",
    "# for i in input[1]:\n",
    "#     testingset.append([i[\"codestate_array\"], [i[\"codestate_label\"]]])\n",
    "# print(run_rnn(trainingset, 5, [6, 8, 8, 8, 6], 0.25, None, testingset, [0, 1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "training = input[:380]\n",
    "testing = input[-126:]\n",
    "trainingset = []\n",
    "testingset = []\n",
    "for student in training:\n",
    "    for codestate in student:\n",
    "        trainingset.append([codestate[\"codestate_array\"], [codestate[\"codestate_label\"]]])\n",
    "\n",
    "for student in testing:\n",
    "    for codestate in student:\n",
    "        testingset.append([codestate[\"codestate_array\"], [codestate[\"codestate_label\"]]])\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95594/95594 [24:17<00:00, 65.58it/s] \n",
      "100%|██████████| 29984/29984 [00:05<00:00, 5869.32it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, F1, weight_list = run_rnn(trainingset, 5, [6, 8, 8, 8, 6], 0.25, None, testingset, [0, 1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[array([[7.61577363e-01, 6.89429702e-48, 3.44714851e-48, ...,\n",
      "        1.03414455e-47, 3.44714851e-48, 3.37820554e-46],\n",
      "       [9.50570444e-01, 6.75865150e-48, 3.37932575e-48, ...,\n",
      "        1.01379772e-47, 3.37932575e-48, 3.31173923e-46],\n",
      "       [9.57846538e-01, 6.75049893e-48, 3.37524946e-48, ...,\n",
      "        1.01257484e-47, 3.37524946e-48, 3.30774447e-46],\n",
      "       [9.12208497e-01, 6.79819079e-48, 3.39909539e-48, ...,\n",
      "        1.01972862e-47, 3.39909539e-48, 3.33111349e-46],\n",
      "       [8.40709274e-01, 6.85589157e-48, 3.42794579e-48, ...,\n",
      "        1.02838374e-47, 3.42794579e-48, 3.35938687e-46],\n",
      "       [6.34632087e-01, 6.89705654e-48, 3.44852827e-48, ...,\n",
      "        1.03455848e-47, 3.44852827e-48, 3.37955770e-46]]), array([[-5.24831486e-01,  8.04803588e-29,  8.51476780e-29,\n",
      "         8.53201096e-29,  8.42294142e-29,  8.24777374e-29,\n",
      "         7.71561636e-29],\n",
      "       [-5.25223039e-01,  8.04524762e-29,  8.51181784e-29,\n",
      "         8.52905503e-29,  8.42002328e-29,  8.24491628e-29,\n",
      "         7.71294327e-29],\n",
      "       [-5.35636310e-01,  7.97113406e-29,  8.43340620e-29,\n",
      "         8.45048459e-29,  8.34245725e-29,  8.16896336e-29,\n",
      "         7.64189093e-29],\n",
      "       [-8.34474385e-01,  5.92302680e-29,  6.26652250e-29,\n",
      "         6.27921276e-29,  6.19894202e-29,  6.07002573e-29,\n",
      "         5.67837956e-29],\n",
      "       [ 4.86138197e-01,  1.35349750e-28,  1.43199125e-28,\n",
      "         1.43489116e-28,  1.41654813e-28,  1.38708889e-28,\n",
      "         1.29759206e-28],\n",
      "       [ 1.18661499e-01,  1.22316434e-28,  1.29409964e-28,\n",
      "         1.29672031e-28,  1.28014359e-28,  1.25352109e-28,\n",
      "         1.17264224e-28],\n",
      "       [ 9.45747381e-01,  1.34534313e-28,  1.42336397e-28,\n",
      "         1.42624641e-28,  1.40801389e-28,  1.37873214e-28,\n",
      "         1.28977450e-28],\n",
      "       [-8.30875012e-01,  5.94632663e-29,  6.29117356e-29,\n",
      "         6.30391374e-29,  6.22332723e-29,  6.09390382e-29,\n",
      "         5.70071701e-29]]), array([[ 2.56626860e-01,  1.62324797e-17,  1.62284867e-17,\n",
      "         1.61224404e-17,  1.32183547e-17,  2.70391835e-17,\n",
      "         2.31280130e-17,  3.14524165e-17,  1.32515542e-17],\n",
      "       [ 1.27409570e-01,  1.55017234e-17,  1.54979102e-17,\n",
      "         1.53966379e-17,  1.26232887e-17,  2.58219293e-17,\n",
      "         2.20868325e-17,  3.00364868e-17,  1.26549937e-17],\n",
      "       [ 8.99539017e-01,  1.71050006e-17,  1.71007929e-17,\n",
      "         1.69890465e-17,  1.39288616e-17,  2.84925813e-17,\n",
      "         2.43711794e-17,  3.31430325e-17,  1.39638457e-17],\n",
      "       [-4.78780671e-01,  1.05781075e-17,  1.05755054e-17,\n",
      "         1.05063989e-17,  8.61391351e-18,  1.76204372e-17,\n",
      "         1.50716718e-17,  2.04963782e-17,  8.63554843e-18],\n",
      "       [ 1.66759516e-01,  1.57413861e-17,  1.57375139e-17,\n",
      "         1.56346759e-17,  1.28184497e-17,  2.62211463e-17,\n",
      "         2.24283035e-17,  3.05008625e-17,  1.28506448e-17],\n",
      "       [-5.78887416e-01,  9.67878140e-18,  9.67640050e-18,\n",
      "         9.61316934e-18,  7.88157861e-18,  1.61223886e-17,\n",
      "         1.37903133e-17,  1.87538238e-17,  7.90137418e-18],\n",
      "       [ 1.43777744e-01,  1.56031573e-17,  1.55993190e-17,\n",
      "         1.54973841e-17,  1.27058878e-17,  2.59908923e-17,\n",
      "         2.22313553e-17,  3.02330273e-17,  1.27378002e-17],\n",
      "       [ 3.76871154e-01,  1.67569926e-17,  1.67528705e-17,\n",
      "         1.66433976e-17,  1.36454734e-17,  2.79128884e-17,\n",
      "         2.38753381e-17,  3.24687243e-17,  1.36797457e-17]]), array([[5.55406508e+00, 2.55019123e-09, 2.40546108e-09, 3.21531276e-09,\n",
      "        1.73029163e-09, 2.44971645e-09, 1.62466917e-09, 2.42388515e-09,\n",
      "        2.68277116e-09],\n",
      "       [5.53027751e+00, 2.61085408e-09, 2.46268115e-09, 3.29179723e-09,\n",
      "        1.77145106e-09, 2.50798925e-09, 1.66331610e-09, 2.48154348e-09,\n",
      "        2.74658776e-09],\n",
      "       [5.54661828e+00, 2.56903071e-09, 2.42323137e-09, 3.23906580e-09,\n",
      "        1.74307411e-09, 2.46781367e-09, 1.63667137e-09, 2.44179154e-09,\n",
      "        2.70259006e-09],\n",
      "       [5.52687137e+00, 2.61965630e-09, 2.47098382e-09, 3.30289517e-09,\n",
      "        1.77742332e-09, 2.51644467e-09, 1.66892379e-09, 2.48990974e-09,\n",
      "        2.75584759e-09],\n",
      "       [5.49717420e+00, 2.69765258e-09, 2.54455360e-09, 3.40123385e-09,\n",
      "        1.83034339e-09, 2.59136798e-09, 1.71861346e-09, 2.56404302e-09,\n",
      "        2.83789876e-09],\n",
      "       [5.53848859e+00, 2.58975483e-09, 2.44277934e-09, 3.26519503e-09,\n",
      "        1.75713532e-09, 2.48772128e-09, 1.64987424e-09, 2.46148923e-09,\n",
      "        2.72439159e-09],\n",
      "       [5.49560682e+00, 2.70183226e-09, 2.54849607e-09, 3.40650364e-09,\n",
      "        1.83317928e-09, 2.59538298e-09, 1.72127624e-09, 2.56801568e-09,\n",
      "        2.84229573e-09],\n",
      "       [5.52141062e+00, 2.63382927e-09, 2.48435244e-09, 3.32076463e-09,\n",
      "        1.78703960e-09, 2.53005924e-09, 1.67795307e-09, 2.50338075e-09,\n",
      "        2.77075739e-09]]), array([[ 6.55155925e+00,  1.33372408e-05,  1.33360026e-05,\n",
      "         1.33368563e-05,  1.33358229e-05,  1.33342302e-05,\n",
      "         1.33364333e-05,  1.33341449e-05,  1.33355336e-05],\n",
      "       [-1.01166357e+00,  4.91817611e-04,  4.91771954e-04,\n",
      "         4.91803434e-04,  4.91765327e-04,  4.91706596e-04,\n",
      "         4.91787836e-04,  4.91703448e-04,  4.91754657e-04],\n",
      "       [ 6.65919894e+00,  1.19815565e-05,  1.19804442e-05,\n",
      "         1.19812111e-05,  1.19802828e-05,  1.19788520e-05,\n",
      "         1.19808311e-05,  1.19787753e-05,  1.19800228e-05],\n",
      "       [-1.01166357e+00,  4.91817611e-04,  4.91771954e-04,\n",
      "         4.91803434e-04,  4.91765327e-04,  4.91706596e-04,\n",
      "         4.91787836e-04,  4.91703448e-04,  4.91754657e-04],\n",
      "       [-1.01166357e+00,  4.91817611e-04,  4.91771954e-04,\n",
      "         4.91803434e-04,  4.91765327e-04,  4.91706596e-04,\n",
      "         4.91787836e-04,  4.91703448e-04,  4.91754657e-04],\n",
      "       [-1.01166357e+00,  4.91817611e-04,  4.91771954e-04,\n",
      "         4.91803434e-04,  4.91765327e-04,  4.91706596e-04,\n",
      "         4.91787836e-04,  4.91703448e-04,  4.91754657e-04]]), array([[3.60202492, 0.09292047, 0.0248891 , 0.09293399, 0.0248891 ,\n",
      "        0.0248891 , 0.0248891 ]])]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(F1)\n",
    "print(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:00<00:00, 585.73it/s]\n"
     ]
    }
   ],
   "source": [
    "input = get_input(students, lables_final_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = input[:380]\n",
    "testing = input[-126:]\n",
    "trainingset = []\n",
    "testingset = []\n",
    "for student in training:\n",
    "    for codestate in student:\n",
    "        trainingset.append([codestate[\"codestate_array\"], [codestate[\"codestate_label\"]]])\n",
    "\n",
    "for student in testing:\n",
    "    for codestate in student:\n",
    "        testingset.append([codestate[\"codestate_array\"], [codestate[\"codestate_label\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95594/95594 [02:26<00:00, 653.68it/s]\n",
      "100%|██████████| 29984/29984 [00:04<00:00, 6441.77it/s]\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, F1, weight_list = run_rnn(trainingset, 5, [6, 8, 8, 8, 6], 0.25, weight_list, testingset, [0, 1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[array([[7.61577363e-001, 2.00738425e-103, 1.00369213e-103, ...,\n",
      "        4.26671681e-102, 1.00369213e-103, 6.48976418e-102],\n",
      "       [9.50570444e-001, 1.96788890e-103, 9.83944451e-104, ...,\n",
      "        4.18276902e-102, 9.83944451e-104, 6.36207786e-102],\n",
      "       [9.57846538e-001, 1.96551515e-103, 9.82757576e-104, ...,\n",
      "        4.17772358e-102, 9.82757576e-104, 6.35440365e-102],\n",
      "       [9.12208497e-001, 1.97940140e-103, 9.89700698e-104, ...,\n",
      "        4.20723894e-102, 9.89700698e-104, 6.39929712e-102],\n",
      "       [8.40709274e-001, 1.99620190e-103, 9.98100949e-104, ...,\n",
      "        4.24294859e-102, 9.98100949e-104, 6.45361223e-102],\n",
      "       [6.34632087e-001, 2.00818773e-103, 1.00409387e-103, ...,\n",
      "        4.26842461e-102, 1.00409387e-103, 6.49236179e-102]]), array([[-5.24831486e-01,  1.62095041e-52,  1.71495463e-52,\n",
      "         1.71842757e-52,  1.69645993e-52,  1.66117950e-52,\n",
      "         1.55399798e-52],\n",
      "       [-5.25223039e-01,  1.62038883e-52,  1.71436048e-52,\n",
      "         1.71783221e-52,  1.69587219e-52,  1.66060399e-52,\n",
      "         1.55345960e-52],\n",
      "       [-5.35636310e-01,  1.60546166e-52,  1.69856763e-52,\n",
      "         1.70200739e-52,  1.68024966e-52,  1.64530635e-52,\n",
      "         1.53914899e-52],\n",
      "       [-8.34474385e-01,  1.19295352e-52,  1.26213680e-52,\n",
      "         1.26469274e-52,  1.24852545e-52,  1.22256049e-52,\n",
      "         1.14367926e-52],\n",
      "       [ 4.86138197e-01,  2.72607176e-52,  2.88416558e-52,\n",
      "         2.89000627e-52,  2.85306168e-52,  2.79372799e-52,\n",
      "         2.61347292e-52],\n",
      "       [ 1.18661499e-01,  2.46356847e-52,  2.60643886e-52,\n",
      "         2.61171713e-52,  2.57833007e-52,  2.52470983e-52,\n",
      "         2.36181218e-52],\n",
      "       [ 9.45747381e-01,  2.70964808e-52,  2.86678944e-52,\n",
      "         2.87259494e-52,  2.83587293e-52,  2.77689670e-52,\n",
      "         2.59772762e-52],\n",
      "       [-8.30875012e-01,  1.19764633e-52,  1.26710175e-52,\n",
      "         1.26966775e-52,  1.25343686e-52,  1.22736977e-52,\n",
      "         1.14817823e-52]]), array([[ 2.56629498e-01,  7.49749747e-27,  7.49565315e-27,\n",
      "         7.44667224e-27,  6.10532600e-27,  1.24889242e-26,\n",
      "         1.06824232e-26,  1.45273191e-26,  6.12066028e-27],\n",
      "       [ 1.27412090e-01,  7.15997543e-27,  7.15821414e-27,\n",
      "         7.11143825e-27,  5.83047668e-27,  1.19266983e-26,\n",
      "         1.02015224e-26,  1.38733289e-26,  5.84512065e-27],\n",
      "       [ 8.99541797e-01,  7.90049018e-27,  7.89854673e-27,\n",
      "         7.84693309e-27,  6.43348908e-27,  1.31602076e-26,\n",
      "         1.12566067e-26,  1.53081668e-26,  6.44964759e-27],\n",
      "       [-4.78778952e-01,  4.88584536e-27,  4.88464349e-27,\n",
      "         4.85272442e-27,  3.97861805e-27,  8.13857594e-27,\n",
      "         6.96134521e-27,  9.46692348e-27,  3.98861084e-27],\n",
      "       [ 1.66762074e-01,  7.27067100e-27,  7.26888248e-27,\n",
      "         7.22138342e-27,  5.92061776e-27,  1.21110890e-26,\n",
      "         1.03592412e-26,  1.40878151e-26,  5.93548813e-27],\n",
      "       [-5.78885843e-01,  4.47046209e-27,  4.46936239e-27,\n",
      "         4.44015701e-27,  3.64036514e-27,  7.44665303e-27,\n",
      "         6.36950774e-27,  8.66206753e-27,  3.64950837e-27],\n",
      "       [ 1.43780279e-01,  7.20682578e-27,  7.20505296e-27,\n",
      "         7.15797100e-27,  5.86862763e-27,  1.20047391e-26,\n",
      "         1.02682747e-26,  1.39641071e-26,  5.88336741e-27],\n",
      "       [ 3.76873877e-01,  7.73975908e-27,  7.73785517e-27,\n",
      "         7.68729157e-27,  6.30260331e-27,  1.28924705e-26,\n",
      "         1.10275972e-26,  1.49967307e-26,  6.31843308e-27]]), array([[6.07620360e+00, 7.50345487e-14, 7.07761400e-14, 9.46044574e-14,\n",
      "        5.09105506e-14, 7.20782700e-14, 4.78028074e-14, 7.13182332e-14,\n",
      "        7.89354586e-14],\n",
      "       [6.06483626e+00, 7.58863938e-14, 7.15796407e-14, 9.56784740e-14,\n",
      "        5.14885231e-14, 7.28965534e-14, 4.83454986e-14, 7.21278881e-14,\n",
      "        7.98315896e-14],\n",
      "       [6.07261403e+00, 7.53025129e-14, 7.10288966e-14, 9.49423100e-14,\n",
      "        5.10923630e-14, 7.23356768e-14, 4.79735214e-14, 7.15729257e-14,\n",
      "        7.92173538e-14],\n",
      "       [6.06323230e+00, 7.60073622e-14, 7.16937438e-14, 9.58309924e-14,\n",
      "        5.15705995e-14, 7.30127557e-14, 4.84225649e-14, 7.22428651e-14,\n",
      "        7.99588469e-14],\n",
      "       [6.04950423e+00, 7.70505742e-14, 7.26777508e-14, 9.71462865e-14,\n",
      "        5.22784134e-14, 7.40148663e-14, 4.90871715e-14, 7.32344089e-14,\n",
      "        8.10562936e-14],\n",
      "       [6.06872744e+00, 7.55937214e-14, 7.13035783e-14, 9.53094691e-14,\n",
      "        5.12899464e-14, 7.26154120e-14, 4.81590437e-14, 7.18497112e-14,\n",
      "        7.95237017e-14],\n",
      "       [6.04879260e+00, 7.71050377e-14, 7.27291233e-14, 9.72149548e-14,\n",
      "        5.23153666e-14, 7.40671840e-14, 4.91218690e-14, 7.32861749e-14,\n",
      "        8.11135885e-14],\n",
      "       [6.06067335e+00, 7.62007507e-14, 7.18761570e-14, 9.60748189e-14,\n",
      "        5.17018126e-14, 7.31985249e-14, 4.85457683e-14, 7.24266755e-14,\n",
      "        8.01622893e-14]]), array([[2.36678550e+001, 2.72639418e-006, 2.72632275e-006,\n",
      "        2.72637171e-006, 2.72631261e-006, 2.72622513e-006,\n",
      "        2.72634729e-006, 2.72622056e-006, 2.72629639e-006],\n",
      "       [5.92126818e+001, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324],\n",
      "       [2.27084213e+001, 7.11626847e-006, 7.11608204e-006,\n",
      "        7.11620983e-006, 7.11605556e-006, 7.11582722e-006,\n",
      "        7.11614609e-006, 7.11581530e-006, 7.11601324e-006],\n",
      "       [5.92126818e+001, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324],\n",
      "       [5.92126818e+001, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324],\n",
      "       [5.92126818e+001, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324,\n",
      "        9.88131292e-324, 9.88131292e-324, 9.88131292e-324]]), array([[1.26212669e+07, 2.27880000e+02, 2.27880000e+02, 2.27880000e+02,\n",
      "        2.27880000e+02, 2.27880000e+02, 2.27880000e+02]])]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(F1)\n",
    "print(weight_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e96c9de0839ff6bf32d8f08b422fc7f200c991bc9f7ca2cb23aa1de27e65a23a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
